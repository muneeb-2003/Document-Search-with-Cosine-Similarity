data perspect robert arizona michigan state univ arizona data especi high dimen data variou data mine machin learn problem perform prepar clean understand data recent prolif big data present substanti challeng opportun featur select survey provid structur overview recent advanc featur select research motiv current opportun era big data revisit featur select research data perspect heterogen data stream data methodolog empha differ similar exist featur select algorithm convent data categor four main group similar base inform theoret base spar learn base statist base method facilit promot research commun also present open sourc featur select repositori exampl show evalu featur select algorithm end survey present problem challeng comput methodolog featur select addit phrase featur select refer format li wang fred robert p trevino tang featur select data perspect articl decemb page introduct era big data huge amount high dimen data becom varieti domain social media healthcar onlin cation rapid growth data present challeng effect effici data manag desir appli data mine machin learn techniqu automat discov knowledg work support address j li k s wang f r p trevino h comput scienc engin temp email michigan email permiss make digit hard copi part work person classroom use grant without fee provid copi made distribut profit commerci advantag copi bear notic full citat first page copyright compon work own other must honor requir prior specif permiss permiss permiss vol articl j al relev redund featur data mine machin learn algorithm appli high dimen data sparser high dimen space adver affect algorithm design low dimen space et al also larg number featur learn model tend may cau perform degrad unseen data data high dimen sig issu mainli categor two main compon featur extract featur low dimen newli construct featur space usual linear nonlinear relev featur extract featur select advantag improv learn per increa comput effici decrea memori storag build better gener model henc regard effect dimen reduct tech understand given learn algorithm featur extract prefer hand featur select maintain physic mean origin featur give model better readabl therefor featur select often prefer mani text mine genet case even though featur dimen often high featur still play essenti cost real world data contain lot irrelev redund noisi featur remov featur select reduc storag comput cost avoid signif loss featur relev featur abl discrimin two class cluster howev given featur f e figur b redund strongli correl figur c featur irrelev featur separ two class cluster therefor remov tradit featur select algorithm supervi perspect accord avail supervi class label unsupervi vol articl select data perspect supervi featur select gener design classif regress problem approxim regress target regress supervi inform train phase highli depend select featur split data train supervi featur select note featur select phase independ interchang unsupervi featur select gener design cluster problem acquir la data particularli expen time effort unsupervi featur select gain consid attent recent without label inform evalu import featur unsupervi featur select method seek altern criteria defin featur rel differ supervi featur select unsupervi featur select usual use instanc avail featur select phase featur select phase independ algorithm filter method reli learn al iter improv qualiti select featur wrapper method emb use standard cluster algorithm n g supervi featur select work suffici label inform avail applic wrapper filter wrapper method reli predict perform predefin learn algorithm evalu qualiti select featur given specif learn algorithm typic wrapper method perform two step search subset featur evalu select featur repeat stop criteria satisfi featur set search compon first gener subset featur learn algorithm act black box evalu qualiti featur base learn perform exampl whole process work iter highest learn perform achiev desir number select featur obtain featur subset give highest learn perform return select featur unfortun known issu larg therefor differ search strategi sequenti search hill climb search best first search john r ta l branch bound search genet algorithm propo yield local optimum learn perform howev search space still extrem huge vol articl j al assess featur import filter method typic comput effici wrapper method howev due lack specif learn algorithm guid featur select phase select featur may optim target learn algorithm typic filter method consist two step first step featur import rank accord featur evalu criteria featur import evalu process either featur multivari scheme rank multipl featur batch way second step typic filter method lowli rank featur filter past decad differ evalu criteria filter method propo repr criteria includ featur discrimin abil separ sampl  nguyen et al h h k ne ta l gao et al featur abil preserv data manifold structur et al g ta l featur abil l includ interact learn algorithm far effici ward note literatur classifi featur select method four categori et h e ne ta l et al hybrid method regard combin wrapper filter ampl differ method togeth result robust henc credibl select featur select data perspect recent popular big data present uniqu challeng tradit featur select li characterist big data veloc varieti necessit develop novel featur select algorithm briefli discuss major concern case singl scan data desir scan either expen impract given dynam maintain featur vol articl select data perspect fig exist algorithm featur select design handl task singl data sourc alway assum data independ ident distribut howev data could come multipl sourc mani applic exampl social media data come heterogen sourc text imag tag video addit link data ubiquit present variou form user post relat user user relat avail multipl data sourc bring unprec opportun leverag share intrin characterist correl find relev featur howev also unequivoc present instanc link inform wide adopt learn algorithm hold appropri util link format featur also exhibit certain type structur well known structur among tree afor reason motiv investig featur select algorithm differ view survey revisit featur select algorithm data perspect categor illustr figur shown data consist static data stream data static data group convent data heterogen data convent data featur either flat possess inher structur tradit featur select algorithm propo deal flat featur featur consid independ past decad wit hundr featur algorithm base technic characterist propo classifi four main group similar base inform theoret base spar learn base statist base method note categor involv filter meth emb method wrapper method exclud reason exclud reconstruct base method featur express structur specif featur vol articl j al multipl could also show new featur fashion size data instanc unknown featur select algorithm make one pass data propo accordingli similarli orthogon set featur also gener dynam stream featur select algorithm design determin one accept newli ad featur remov exist outdat featur differ exist survey current exist survey give summar featur select et al recent advanc featur select data perspect survey intro duce repr featur select algorithm cover compon mention figur also relea featur select repositori python name built wide use machin learn packag two comput packag n includ near repr featur select algorithm web page repositori avail notat summar symbol use throughout survey tabl l p p e r c e charact matric bold lowerca charact vector calligraph f column j j trace astr matrix norm defin n j n j vector defin n n ident matrix featur select convent data sinc hundr featur select algorithm propo sec base inform theoret base spar learn base statist base method similar base method differ featur select algorithm exploit variou type criteria defin relev featur among famili method assess featur import abil preserv data similar refer similar base method supervi featur select data similar deriv label inform unsupervi featur select method method take advantag differ distanc metric measur obtain data similar vol articl select data perspect tabl symbol notat n k c class f      x xs given x among instanc encod affin matrix suppo want select relev one way maxim util max w h e r denot util featur subset s algorithm famili often evalu featur individu util maxim scan form max f f f f util function featur transform scale nor etc result origin featur vector new affin matrix obtain affin matrix s maxim problem equat show would select subset problem usual solv greedili select top maxim individu discuss repr algorithm group reformul unifi framework score score et al unsupervi featur select algorithm select featur best preserv data manifold structur consist three phase first construct affin matrix j among neighbor otherwi j diagon matrix di defin n j matrix last score vol articl j al score evalu featur individu task select solv greedili pick top smallest score standard data varianc featur term interpret normal featur vector therefor obviou score special case util maxim equat spec spec exten score work supervi unsupervi scenario exampl unsupervi scenario data sim measur kernel supervi scenario data similar de fine j otherwi w h e r number data sampl class af ter obtain affin matrix sand diagon matrix normal matrix d s d basic idea spec similar score featur j j n j j n j j j j j j function x featur work equat set n i i sm respect matrix fisher score fisher score et al supervi featur select algorithm select featur featur valu sampl within class similar vol articl select data perspect c c n number sampl class j mean valu featur mean valu featur sampl class j varianc valu featur sampl class j respect similar score top obtain greedili select long affin matrix j otherwi way relationship fisher score score henc framework  entri entri trace ratio score select k w tr w data similar instanc class minim data similar instanc differ class howev trace ratio problem difficult solv close form solut henc trace ratio problem often convert tractabl format call ratio trace problem maxim tr w w altern wang et al propo iter algorithm call solv trace ratio al differ score batch mode fisher score exampl batch mode fisher score within class data similar between class data similar sw j j otherwi maxim k k constant reduc uni similar base featur select framework set f hand batch mode score within class data similar between class data sw j e n p n p xi case trace ratio criterion score w tr w k k therefor maxim trace ratio criterion also equiv solv unifi maxim prob equat select featur separ instanc differ class assum instanc randomli select among vol articl j al follow cl nh j x j x r nm j x j x r j j nearest instanc class class respect p y q nm j j maxim equat discuss supervi unsupervi learn problem categori method straight forward simpl comput focu build affin matrix afterward find inform theoret base method larg famili exist featur select algorithm inform theoret base method algorithm famili exploit differ heurist filter criteria measur import featur usual measur correl class label algorithm famili perform supervi way addit inform theoret concept appli discret variabl therefor featur select algorithm famili work discret data continu featur valu data techniqu requir beforehand two decad research inform theoret criteria unifi condit likelihood maxim framework brown et al subsect introduc repr algorithm famili first give brief introduct follow h x xi xp xi lo p xi specif valu random variabl x p xi denot probabl x second h xi xp lo p prior probabl w h l condit probabl vol articl select data perspect x x h xi x xi lo p xi p xi p xi joint probabl inform gain symmetr x x last condit inform gain mutual inform discret variabl x given x h z xi x xi lo p xi p p featur select problem forward sequenti search featur ad criterion score gener j unifi condit likelihood maxim featur select framework select criterion score fora new follow function two variabl f linear function two variabl refer criterion linear combin shannon inform si si  mim inform gain lewi measur import featur help achiev good classif perform mutual inform score featur observ mim score featur assess individu therefor featur correl consid featur redund complet ignor obtain mim featur score featur choo featur highest featur score add select featur set process repeat desir number equat zero vol articl j al mutual inform featur select limit mim criterion assum featur independ realiti good featur strongli correl class label also highli correl word correl featur minim mutual inform featur se lection consid featur relev featur redund featur select phase featur score new unselect featur formul follow si featur relev evalu second term penal featur term zero minimum redund maximum relev peng et al propo minimum re maximum relev criterion set valu rever number si henc select featur effect featur redund gradual reduc intuit non redund featur select becom difficult new featur redund featur alreadi s brown et al give anoth interpret pairwi independ featur becom stronger also strongli link condit likelihood maxim framework it zero nixon show contrast minim featur redund con redund unselect featur alreadi select featur given class label also maxim word long featur redund given class label featur select argument condit featur extract lin tang new si si compar add third term si maxim condit also special case linear combin shannon inform term er et propo increa complementari inform share vol articl select data perspect si directli reduc condit likelihood maxim framework brown et al author demonstr simpl manipul criterion si si therefor also special case linear combin shannon inform term condit mutual inform maxim previou mention criteria could reduc linear combin shannon inform term next show al reduc non linear combin shannon inform term among condit mutual inform maxim label given select featur far mathemat select phase featur note valu small strongli correl class label redund si known select featur maxim minimum valu guarant select featur strong predict abil reduc deriv max i therefor also special case condit likelihood maxim framework equat select criterion call inform fragment featur score new unselect i intuit behind inform fragment addit new featur rule equiv form henc equat equat restrict term i nonneg vol articl j al i appar i doubl input symmetr relev anoth class inform theoret base exploit normal al si h framework fast correl base filter inform theoret base featur framework fast correl base filter exampl exploit featur class correl featur featur correl simultan algorithm work follow given predefin threshold select subset featur highli late class label w h e r symmetr uncertainti xs xs h xs specif featur call predomin exist featur featur consid redund set redund featur denot w h c h split contain redund featur featur respect differ heurist appli pi n remov redund featur keep featur relev discuss unlik similar base featur select algorithm fail tackl featur similar similar base method categori method independ learn algorithm henc generaliz howev exist inform theoret base still clear assess import featur addit method handl spar learn base method third type method spar learn base method aim minim fit er along spar regular term spar forc mani featur co small exactli zero correspond featur simpli spar learn base method receiv consid attent recent year due good perform follow part review spar learn base featur select method supervi unsupervi perspect vol articl select data perspect first coeffici min w x w p loss function wide use loss function loss includ least squar loss w p regular paramet balanc contribut loss function spar regular typic regular term directli seek optim set featur regular problem regard tightest convex relax one lasso wei et al w e n u also spar vector rank featur normal higher valu import correspond like featur select phase consist multipl target word want multipl predict model differ target share paramet sparsiti featur either small score larg score target problem gener p follow min w x w p q w p c j q p q paramet ai use control loss function sparsiti induc regular term featur w case find relev featur across multipl target intuit way use discret optim regular optim problem follow min w x w howev solv afor optim problem proven np hard also due discret natur object function also convex solv variat g ta l et al author provid two algorithm proxim gradient vol articl j al q q case although desir featur sparsiti howev inher non convex non smooth henc regular prefer wide use differ scenario multi task learn et al et al anomali detect li et al w ta l decad et al g ta l n ta l et al l ta l h ta l et al n h e n j ne ta l et al n ta l et al l ta l similarli regular thu follow discuss spar learn base featur select center around regular term regular also strong connect problem case addit regular term regular row effici robust featur select n ta l propo effici robust featur select ref method employ joint minim loss noisi data loss function robust noi reason norm regular featur select model ad loss min w w howev et j learn model supervi class label featur select phase deriv spar featur coeffici howev sinc label data costli time featur vol articl select data perspect l flat emb unfold data manifold obtain spectral cluster techniqu second step sinc emb data known take advantag specif given minim min featur coeffici vector emb solv regress problem obtain featur coeffici vector vector correspond one emb x third step featur h c f score featur comput j j higher score regular discrimin featur select yang et al author propo new unsupervi featur select algorithm select featur exploit discrimin inform featur correl first center data matrix weight label indic matrix n instead use global inform propo util local discrimin inform select nativ featur advantag use local discrimin inform twofold first demonstr import global discrimin inform mani cluster task second consid local discrimin inform xi p nearest np xi xi local data matrix around xi local total scatter matrix local class scatter matrix center data matrix gi et h g subset obtain lection matrix pi g without label inform unsupervi w xi low dimen space gi rs follow definit global discrimin format yang et al local discrimin score instanc id b w x p id fore w also incorpor achiev featur select object min w tr w featur select use nonneg spectral analysi nonneg discrimin select li et al perform spectral cluster featur select joint framework select subset discrimin featur assum pseudo vol articl j al  indic matrix easi show adopt strategi learn local geometr structur preserv minim normal graph tr w h e r matrix deriv kernel addit given pseudo label g assum exist linear transform matrix w data instanc pseudo label g pseudo class label util constraint guid featur select process problem min g w paramet control sparsiti model introduc balanc discuss spar learn base featur select method gain increa popular recent year merit type method emb featur select typic learn algorithm linear regress etc thu often lead good perform underli learn algorithm also sparsiti featur weight model pose good enabl us explain make predict nonetheless still drawback method first directli optim particular learn algorithm featur select select featur necessari achiev good perform learn task second kind method often involv solv non smooth optim problem multipl inver etc statist base method filter base method addit statist base algorithm analyz featur individu henc featur redund inevit ignor select phase low varianc low varianc elimin featur whose varianc predefin prune vol articl select data perspect t score t score davi sampson use binari classif problem differ class correspond standard deviat basic idea t score assess whether featur make mean two class t score chi squar score chi squar score util test n n w h e r indic number data instanc featur valu given featur n number data instanc class r higher chi squar score indic import index index also wide use statist measur quantifi featur abl separ instanc differ class given featur featur valu suppo set instanc featur valu smaller equal featur valu larger featur valu respect word featur valu separ index score w w denot probabl instanc p condit probabl class binari classif index take maximum valu also relev basic idea hall smith use correl base heurist k numer indic predict power featur set denomin show much redund featur set basic idea good featur subset correl featur featur correl use symmetr uncertainti et al find global optim subset comput prohibit adopt best search strategi find local optim featur subset begin comput util vol articl j al featur consid featur class featur featur correl start empti set expand set featur highest util satisfi discuss statist base featur select method reli predefin statist select method method often evalu import featur individu henc handl featur redund meanwhil algorithm famili work di data convent data techniqu requir numer method hybrid featur select method kind ensembl base method aim construct group featur subset differ featur select algorithm produc gate result group way instabl perturb issu singl consist two step construct set differ featur select result aggreg differ output consensu result differ method differ way two step perform first step exist method either ensembl select featur subset singl method differ sampl subset ensembl select featur subset multipl sampl exampl et al studi ensembl featur select aggreg train data et al author improv stabil featur select algorithm appli multipl random sampl origin data second step method method et al also wide use addit use aggreg function et nowaday deep learn techniqu popular success variou real world repr featur select directli find relev featur origin featur even though deep learn mainli use featur learn still attempt use deep learn techniqu featur select briefli review deep learn base featur select method exampl li et al deep featur select model propo select featur input level deep neural network typic add spar one one linear layer input layer first hidden layer multilay vol articl select data perspect make neuron contribut classif phase sinc heterogen multi view preval machin learn pattern recognit applic et al featur select first extract new unifi repr featur group use lasso method wang et al author propo attent neural network guid featur select cognit bia consist two modul segment modul classif modul first given cognit bia vector segment modul segment object belong one class input imag classif modul reconstruct function appli segment gate raw imag threshold classif featur sensit cognit bia cognit bia activ featur recent data reconstruct error emerg new criterion featur select especi unsupervi featur select defin featur relev capabl featur select sparsiti constraint et al use project matrix project origin featur select graph regular data reconstruct basic idea make data sampl via linear reconstruct pass effici unsupervi featur select propo schweitzer regard modif classic pivot qr algorithm basic idea still select repr featur minim recon function li et al argu reconstruct function necessarili linear featur structur featur flat mani real applic featur could exhibit variou kind structur exampl spatial tempor smooth disjoint group overlap group tree graph et al  w e case featur select algorithm incorpor knowledg structur one motiv exampl studi array featur vol articl j al fig illustr lasso group lasso spar group lasso featur set divid four group n column dark color denot select featur column light color denot popular success approach achiev featur select structur featur minim term w x w g structur among featur ai paramet loss penalti w g alli set spar regular term note afor formul similar equat differ featur select structur featur featur select structur first featur could exhibit group structur one common exampl analysi varianc factor associ sever group express set dummi featur yuan lin exampl includ differ frequenc band repr group signal process et al gene similar function act group et al therefor group lasso group lasso yuan lin jacob et al meier et al lasso group lasso shown illustr exampl figur suppo featur come four differ group overlap group four differ group contrari group lasso tend select select featur differ group whole shown figur group lasso select second fourth group featur two group select mathemat group gi perform regular previou term follow min w x weight group consid prior measur vol articl select data perspect spar group lasso group lasso select group featur select desir consid intrin featur structur select featur differ select group simultan illustr figur spar group lasso friedman et al min w x w paramet balanc contribut inter group sparsiti sparsiti featur select differ among lasso group lasso spar figur overlap spar group lasso method consid disjoint group among featur howev group may also overlap jacob et al group mention ye differ group gene may overlap one may belong multipl group gener overlap spar group lasso regular similar regular term spar group lasso differ gi featur select tree featur structur addit group structur featur also exhibit tree structur exampl face recognit face recent tree guid group lasso propo handl featur select featur repr index tree kim ye tree guid group lasso tree guid group lasso ye structur featur repr tree leaf node featur intern node denot group featur intern node consid root weight repr height tightli featur correl gi gi gi denot whole set node featur level root node level number node level node tree guid group lasso satisfi follow two condit intern node depth level non overlap indic gi j gi gi parent node gi j h e n gi j gi m eight featur organ index tree depth intern node level root node index tree addit intern vol articl j al fig illustr tree structur among featur eight featur form simpl index tree ad e p ho node level overlap parent node child node min w x j j regular paramet hi predefin paramet measur contribut intern node gi j sinc parent node child node thu parent select child node exampl illustr figur intern node select child node select featur select structur mani case featur may strong pairwi interact exampl natur languag process strong pairwi depend gene sinc featur show certain kind depend case model undirect graph node repr featur edg among node show pairwi depend featur et al k g n e assum set n e h e e featur pairwi featur depend graph lasso sinc featur exhibit graph structur two node featur connect edg g n e featur like select togeth similar featur coeffici one way achiev target via graph graph featur graph basi lasso ye min w x w j vol articl select data perspect first regular term w lasso second term ensur larg j equat graph lasso encourag featur connect togeth similar featur coeffici howev featur also neg correl case featur n e repr sign graph posit neg edg min w x w j j correl two featur two featur correl j n j penalti term forc featur similar hand two featur neg correl j j dissimilar major limit use pairwi sampl correl address limit yang et al propo put regular enforc pairwi featur coeffici equiv two min w x w j max afor formul regular use featur select pose max w h e r spar nonzero discuss featur structur often given still challeng problem automat featur tradit featur select algorithm heavili base data assumpt howev partial fuse togeth effect featur select challeng problem anoth exampl social media platform instanc high dimen often link togeth find way integr link inform guid featur select anoth difficult prob section review current featur select algorithm heterogen data multi way first multi sourc featur select aim select featur origin featur space vol articl j al integr multipl sourc multi view featur select select featur differ featur space view simultan second multi sourc featur select normal sourc featur select data facebook user connect friendship biolog system protein interact due differ link exampl link data repr figur show eight link instanc featur inform illustr left part figur b link b long c h e ne ta l activ learn et al h ta l relat among data instanc take advantag relat featur select label recent year wit surg research interest perform featur select et al next introduc repr algorithm famili featur select network han author propo supervi tail x denot content matrix one hot label matrix matrix instanc first attempt learn linear classifi w min w w w f term w includ achiev joint featur sparsiti across differ class w vol articl select data perspect min w w w tr w w graph regular balanc contribut content format inform featur select social media data tang investig featur select problem social media data evalu variou social relat follow four type relat support social correl theori mcpherson et al social influenc x p p j relat among user featur select framework author propo add topic min w w u u pi x w x j w set post user u paramet sparsiti win row unsupervi featur select link data link unsupervi featur select denot pseudo label matrix row one nonzero entri also assum linear map matrix w featur first consid constraint link inform employ social dimen approach tang obtain hidden factor incur interdepend among instanc accord linear discrimin analysi within total hidden factor scatter matric sw sb n defin n r e h h weight hidden factor matrix consid fact instanc similar hidden factor similar instanc differ hidden factor dissimilar constraint link inform incorpor maxim tr st second tr min st regular paramet balanc contribut two constraint achiev featur select add regular term w n h eventu min w ff w w x id win row vol articl j al model featur select separ featur select heavili depend lot noisi link network li et al propo robust let x instanc min w w f select two phase could help boost featur inform help author extend model dynam case obtain subset relev li et addit posit link mani real world network also contain neg link distrust relat foe slashdot base author et al studi neg link ad valu posit link find relev featur select mani learn task often multipl data sourc set data instanc given repr  select subset relev featur target sourc xi take advantag inform multi sourc featur select via geometri depend covari analysi learn global geometr pattern sourc reflect intrin relationship among instanc multipl local geometr pattern multipl affin matric si w h e r data sourc contribut sourc global geometr pattern obtain multipl data sourc one build geometri depend sampl covari matrix target sourc n xi w h e r e diagon matrix j j n diagon k k n k j get geometri depend sampl covari matrix subsequ question use effect featur select basic two method propo first method sort diagon covari matrix select featur vol articl select data perspect differ highest varianc select featur base approach equiv choo featur consist global geometri pattern second method appli spca featur select multi view data facet data instanc differ featur space natur depend high dimen henc task multi view featur select ari et al n ta l w n ta l et al aim select featur differ featur space simultan use relat one mo exampl select relev featur pixel tag term associ imag simultan sinc multi view featur select design select featur across multipl lasso friedman et al p e n ta l subsect review repr algorithm adapt multi view featur select adapt unsupervi multi view featur lection et al take advantag data cluster structur data similar correl among view simultan specif let respect concaten data u f use min w f w joint sparsiti use spectral cluster affin matrix differ view learn share pseudo class label data matrix view first build affin data similar view get correspond matrix vol articl j al w weight summat paramet balanc contribut  select differ view learn pseudo class label differ learn one featur weight matrix view fit pseudo class label joint least squar loss featur identifi stop sign address issu multi view featur select novel featur select algorithm propo wang et al joint group regular featur weight matrix view group de w c captur global relat among differ view abl achiev sparsiti view select addit group wi also includ achiev featur sparsiti among select view henc object function min w f w w discuss featur select algorithm heterogen data handl variou type data propo algorithm famili use matric repr data often convert requir complex matrix oper comput expen limit scalabl vol articl select data perspect algorithm larg scale data design effici distribut algorithm speed featur case mani real world like face data stream practic wait data instanc featur avail perform featur select relev featur time manner orthogon set featur select stream featur also practic signif exampl twitter produc featur therefor algorithm featur select featur stream constant candid featur arriv one time task time select subset relev featur featur seen far perkin theiler z h ta l w u et ta l l ta l time step typic stream featur select algorithm first determin whether accept recent arriv featur featur ad select featur set determin whether discard exist featur process repeat new featur show anymor differ algorithm differ implement first step second step check exist featur option step graft algorithm first attempt perform stream featur select credit perkin theiler method base gradient descent regular risk framework perkin et al graft gener techniqu deal varieti model featur weight vector regular lasso model involv ad new penalti term model exampl time step j new featur incur regular penalti therefor addit new featur object function valu lasso reduct loss function part loss w x outweigh increa regular loss w x step new featur accept includ model graft adopt conjug gradient cg procedur optim model respect current paramet exclud alpha invest algorithm alpha invest et al adapt complex penalti method dynam chang threshold error reduct requir vol articl j al fdr arriv featur small portion spuriou featur affect raci significantli detail algorithm work follow initi probabl fal posit index featur select featur model empti new featur arriv set sf r ai sf denot accept number fal posit detect featur current moment featur ad model otherwi featur v l u n gt h c h equiv t statist p valu denot lower onlin stream featur select algorithm research studi stream irrelev redund weakli relev non redund strongli relev featur optim featur select select non redund strongli relev featur featur continu arriv stream fashion difficult find strongli relev non redund featur analysi step discov weakli relev strongli relev featur featur ad best candid featur otherwi newli arriv featur remov unsupervi stream featur select social media vast major stream featur select howev social media easi amass vast quantiti unlabel data time labor consum obtain label deal larg scale unlabel data social media li et al propo algorithm tackl unsupervi stream select key idea util sourc inform link inform first uncov hidden social factor link inform mix membership stochast instanc take advantag constraint perform select specif time l e w denot correspond featur matrix featur coeffici respect model featur inform construct graph repr featur similar denot adjac matrix graph l correspond matrix x step follow min w x w w w x w l f vol articl select data perspect spar regular paramet robust model bal link inform featur inform assum next time step new featur arriv test new featur take similar strategi graft perform test specif inclu new featur go reduc object function equat featur accept otherwi new featur remov therefor method boyd featur select data stream onlin featur select wang et al onlin featur select algorithm binari classif propo let   denot sequenc input data instanc input class label respect data instanc xi classifi w w achiev featur select requir linear classifi w b nonzero el w indic use classif get w new instanc misclassifi n b r new classifi truncat take import subset anymor unlabel data continu gener huang et al p r v e l unsupervi featur select method one pass data limit storag basic idea use matrix sketch effici maintain low rank coeffici use obtain import featur author empir show orthogon condit satisfi ridg regress replac lasso featur select comput effici assum x minim min w b w w f sketch matrix x l vector locat locat solv optim problem equat j j discuss data gener featur select algorithm featur data stream often desir practic usag vol articl j al deal new data sampl new featur arriv howev mention algorithm requir multipl pass data even need store memori disk storag requir effort design stream algorithm effect perform evalu featur select repositori first introduc attempt develop featur select h e purpo featur select repositori collect wide use featur select develop featur select research serv platform comparison assist research achiev reliabl evalu process develop new featur age repositori avail interact tool metric exampl empir show evalu perform featur select repositori experi result obtain repositori project websit list applic featur select algorithm along evalu either classif cluster next provid detail inform algorithm evalu categor follow two criteria label supervi unsupervi output select next output featur score qualiti first featur evalu respect featur subset select method output vol articl select data perspect supervi method test perform supervi featur select algorithm divid whole two part train set test featur select test set select featur act input classif model test purpo experi use classif accuraci evalu classif perform three classif model linear deci tree bay use get reliabl result cross valid use normal higher classif perform unsupervi method follow standard way assess unsupervi featur select evalu unsupervi algorithm term cluster perform two commonli use accuraci acc use featur select algorithm first appli select featur sinc also list follow inform main algorithm review articl tabl type data convent data type data usag label supervi output featur weight subset select featur type numer discret variabl numer variabl also divid continu variabl discret variabl supervi featur select method also list method de sign tackl binari class multi class classif problem base afor inform practit intuit sen applic scenario open sinc signif number attempt develop featur discuss scalabl tremend growth size data scalabl current featur select algorithm may jeopard mani scientif busi applic data usual measur terabyt normal scale terabyt load memori directli therefor limit usabl featur select algorithm current attempt use distribut program framework perform parallel featur select larg scale singh et al et al et al et al addit exist featur select method time complex proport w h e r featur dimen recent big data ultrahigh dimen emerg mani real world text mine inform retriev featur select algorithm scale well ultrahigh dimen data whose effici deterior quickli even comput infea case well design featur select algorithm linear run time prefer fan et al tan et al moreov onlin classif onlin cluster task scalabl featur select algorithm also big issu select regress also regard supervi method focu featur select vol articl j detail main featur select data output featur type binari multi class unsupervi rank categor continu discret score et et spec mim lewi peng lin meyer et meyer q regular et ref et al li et et t score davi chi squar continu vol articl select data perspect tabl continu data output featur featur type binari multi class unsupervi rank categor continu discret spar friedman et tree lasso graph lasso link multi sourc perkin theiler alpha invest wu et li stream wang et vol articl j al exampl data stream featur stream may infinit load memori comput expen even though featur select algorithm reduc issu scalabl onlin classif cluster method either requir keep featur memori requir iter process visit data instanc limit practic usag conclu even though preliminari work increa scalabl featur select algorithm believ focu given stabil supervi featur select algorithm perform usual evalu accuraci addit accuraci stabil algorithm also import featur select algorithm perturb train data et al h ea n u et al et al yang mao perturb data could variou format data sampl inclu sampl rigor definit stabil featur select algorithm refer exampl indic domain expert would like see set similar featur domain number data instanc contrast supervi featur select stabil unsupervi featur select algorithm well studi yet studi stabil unsupervi featur select much difficult supervi method reason unsupervi featur select enough prior knowledg cluster structur data thu uncertain new data instanc perturb belong exist cluster introduc new cluster supervi belong exist class consid outlier need modifi select featur set adapt outlier word unsupervi featur featur select algorithm especi featur weight method spec number select featur howev often unknown optim number select featur larg number select featur increa risk includ noisi redund hand also good includ too small number select featur sinc relev whole process comput expen still open challeng problem determin optim number select featur addit optim number vol articl select data perspect featur select algorithm real world problem usual limit knowledg cluster structur data choo differ number cluster may merg total differ small cluster one big cluster split one big cluster smaller one may result find total differ subset featur work done mate number suitabl cluster propo howev still clear find best number cluster directli unsupervi featur select believ conclu effect machin learn data mine includ web text imag object featur select includ build simpler comprehen model improv data wit develop mani new featur select method survey articl aim review recent advanc featur select algorithm data perspect particular data featur select stream data specif classifi convent inform theoret base spar learn base statist base method type meth accord use techniqu featur select structur featur consid three type structur featur name group tree graph featur third part studi sourc multi view featur select last part consist featur select algorithm type featur select algorithm facilit research featur select suggest given evalu featur select algorithm either supervi featur select algorithm other provid comprehen structur list recent advanc featur select algorithm data featur select refer diagnosi  vol articl j al salem effect characterist select salem tang featur select cluster review data cluster algorithm applic unsupervi supervi review   network stephen press work inform theoret    laurent el michael i jordan r g direct formul spar john statist geolog robust  richard peter pattern classif john wiley son select inform    jun adapt unsupervi multi view featur select visual jerom friedman trevor robert note group lasso spar group lasso  introduct pattern recognit gao greg aram variat inform maxim featur select c w variabl mutabl contribut studi statist distribut optim marina li han local preserv featur learn  vol articl select data perspect li li fisher score li mark s nixon gait featur subset select mutual inform ieee introduct  springer mark hall lloyd smith featur select machin learn compar correl base filter solut trevor robert jerom friedman jame franklin element statist learn data mine   stabl featur select discoveri biol chem wu featur select via joint emb learn spar regress tang gao activ learn network text huang unsupervi featur select data stream  laurent jacob jean philipp vert group lasso overlap graph lasso  machin learn base interact  re julien franci r bach proxim method spar li  julien melani hilario stabil featur select algorithm studi high syst  kim eric p tree guid group lasso multi task regress structur sparsiti  john select  r g peter bartlett laurent el michael i jordan learn kernel  david d lewi featur select featur extract text categor proceed workshop speech natur languag   li wu robust unsupervi featur select network data  li tang reconstruct base unsupervi featur select emb vol articl j al li li chen wyeth w deep featur select theori applic identifi enhanc li yang lu unsupervi featur select use nonneg  lin tang condit learn integr framework featur extract fusion mao  comput method select featur numer  jun ye multi task featur learn via effici minim jun ye spar learn effici project arizona state univ re jun group tree structur structur preserv featur select tran syst long mark wu philip s spectral cluster multi type relat data steven group song huang supervi group lasso applic data analysi foster provost classif network data toolkit case studi j mach  glenn jennif g dy convex princip featur select crystal schweitzer unsupervi ieee  sociol patrick e meyer use variabl complementar featur select cancer applic comput patrick emmanuel meyer cola inform theoret featur select mi sign process ieee michael melani bernhard siegfri johann wolfgang christian new ensembl base algorithm identifi breath ga marker candid liver disea nguyen jeffrey chan simon romano jame bailey effect global approach mutual huang chri h ding effici robust featur select via joint trace ratio criterion featur report statist depart berkeley vol articl select data perspect peter ron weiss vincent other machin learn python j mach oct hanyang peng yong fan direct sparsiti optim base featur select multi class classif peng long chri ding featur select base mutual inform criteria max depend max relev min redund  fast re simon perkin use unsupervi igor theoret empir analysi mach learn roy k sri rama c krishna featur select use deep neural network thoma yve van de peer robust featur select use ensembl featur select tech  ted john p lyle h regular learn network featur data  ture cut imag segment ieee tran pattern anal mach  alexand anastasia ilia effici high order interact awar featur select base condit mutual inform singh jeremi scott larsen parallel larg scale featur select logist regress tan w li wang toward ultrahigh dimen featur select big data j mach tang salem featur select classif review data classif applic tang gao unsupervi featur select multi view data social media tang gao discrimin analysi unsupervi featur select  link social shrinkag lasso j stat robert trevor estim number cluster data set via gap vol articl j al c univ cambridg michel object recognit inform featur linear classif  reduct wang ye multi layer featur reduct tree structur group lasso via hierarch project wang steven c h onlin featur select applic ieee wang sen song attent neural network featur select use cog wei  wei philip s effici partial order preserv unsupervi featur select net work wei philip s unsupervi featur select preserv stochast neighbor wu li glean wisdom past earli detect emerg rumor wu xu gao huang q alic x gradient boost featur select yin chang minimum redund maximum data yang k z mao robust featur select data base fusion  howard yang john e moodi data visual featur select new algorithm sen yang lei yuan peter ye featur group select yang tao huang regular discrimin featur select process synthesi method wu wei ding pei toward scalabl accur onlin featur select big data lei featur select high dimen data fast correl base filter solut  jun method ming yuan lin model select estim regress group variabl j roy stat soc b diver yang flexibl latent variabl model multi task learn mach peng long wei ding wu toward mine trapezoid vol articl select data perspect group lasso peng rocha bin composit absolut penalti famili group hierarch statist eng  multi sourc featur select via geometri depend covari analysi  jame cox david warren massiv parallel featur select mach learn dean foster robert stine lyle stream featur select use alpha invest jun progress spar group lasso random algorithm robert j support vector machin  coupl dictionari learn unsupervi receiv septemb accept august vol articl 